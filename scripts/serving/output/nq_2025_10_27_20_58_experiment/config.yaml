model2path:
    e5: intfloat/e5-base-v2
    bge: BAAI/bge-base-en-v1.5
    contriever: facebook/contriever
    llama2-7B-chat: meta-llama/Llama-2-7b-chat-hf
    llama2-7B: meta-llama/Llama-2-7b-hf
    llama2-13B: meta-llama/Llama-2-13b-hf
    llama2-13B-chat: meta-llama/Llama-2-13b-chat-hf
model2pooling:
    e5: mean
    bge: cls
    contriever: mean
    jina: mean
    dpr: pooler
method2index:
    e5: null
    bm25: null
    contriever: null
    clip:
        text: path/to/text_index
        image: path/to/image_index
data_dir: dataset/
save_dir: output/nq_2025_10_27_20_58_experiment
gpu_id: 0,1,2,3,4,5,6,7
dataset_name: nq
split:
- test
test_sample_num: null
random_sample: false
seed: 2024
save_intermediate_data: true
save_note: experiment
retrieval_method: intfloat/e5-base-v2
retrieval_model_path: intfloat/e5-base-v2
index_path: /path/to/your/indexes/e5_flat_inner.index
multimodal_index_path_dict: null
faiss_gpu: true
corpus_path: /path/to/your/retrieval_corpus/wiki.jsonl
instruction: null
retrieval_topk: 5
retrieval_batch_size: 256
retrieval_use_fp16: true
retrieval_query_max_length: 128
save_retrieval_cache: false
use_retrieval_cache: false
retrieval_cache_path: null
retrieval_pooling_method: mean
bm25_backend: bm25s
use_sentence_transformer: false
use_reranker: false
rerank_model_name: null
rerank_model_path: null
rerank_pooling_method: null
rerank_topk: 5
rerank_max_length: 512
rerank_batch_size: 256
rerank_use_fp16: true
use_multi_retriever: false
multi_retriever_setting:
    merge_method: concat
    topk: 5
    rerank_model_name: null
    rerank_model_path: null
    retriever_list:
    -   retrieval_method: e5
        retrieval_topk: 5
        index_path: null
        retrieval_model_path: intfloat/e5-base-v2
        instruction: null
        bm25_backend: bm25s
        use_reranker: false
        corpus_path: null
        use_sentence_transformer: false
        retrieval_pooling_method: mean
        retrieval_use_fp16: true
        retrieval_query_max_length: 128
        faiss_gpu: true
        retrieval_batch_size: 256
        rerank_model_name: null
        rerank_model_path: null
        retrieval_cache_path: null
        save_retrieval_cache: false
        use_retrieval_cache: false
    -   retrieval_method: bm25
        retrieval_topk: 5
        index_path: null
        retrieval_model_path: bm25
        instruction: null
        bm25_backend: bm25s
        use_reranker: false
        corpus_path: null
        use_sentence_transformer: false
        retrieval_pooling_method: mean
        retrieval_use_fp16: true
        retrieval_query_max_length: 128
        faiss_gpu: true
        retrieval_batch_size: 256
        rerank_model_name: null
        rerank_model_path: null
        retrieval_cache_path: null
        save_retrieval_cache: false
        use_retrieval_cache: false
framework: fschat
generator_model: llama3-8B-instruct
openai_setting:
    api_key: null
    base_url: null
generator_model_path: llama3-8B-instruct
generator_max_input_len: 1024
generator_batch_size: 4
generation_params:
    max_tokens: 32
use_fid: false
gpu_memory_utilization: 0.85
metrics:
- em
- f1
- acc
- precision
- recall
- input_tokens
metric_setting:
    retrieval_recall_topk: 5
    tokenizer_name: gpt-4
save_metric_score: true
dataset_path: dataset/nq
gpu_num: 8
device: cuda
